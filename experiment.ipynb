{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlufjzQHQq_R"
   },
   "source": [
    "# Neurons That Panic \u2014 Core Experiment Notebook\n",
    "\n",
    "This notebook reproduces the main experiments from the paper:\n",
    "\n",
    "- adversarial trigger generation\n",
    "- activation extraction (clean vs adversarial)\n",
    "- |\u0394norm| computation and ranking\n",
    "- positional and layerwise analyses\n",
    "- causal patching\n",
    "\n",
    "Running this notebook top-to-bottom will generate all figures and CSV outputs used in the paper. Sanity checks are handled in a separate notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hGV6MDRm_wbx",
    "outputId": "9b7d60b1-f494-4e62-f88e-96dfdf3c0c85"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformer_lens in /usr/local/lib/python3.12/dist-packages (2.16.1)\n",
      "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (1.12.0)\n",
      "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.14.1)\n",
      "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.0.3)\n",
      "Requirement already satisfied: datasets>=2.7.1 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (4.0.0)\n",
      "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.8.1)\n",
      "Requirement already satisfied: fancy-einsum>=0.0.3 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.0.3)\n",
      "Requirement already satisfied: jaxtyping>=0.2.11 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.3.3)\n",
      "Requirement already satisfied: numpy<2,>=1.26 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (2.2.2)\n",
      "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (13.9.4)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.2.1)\n",
      "Requirement already satisfied: torch>=2.6 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (2.9.0+cu126)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (4.67.1)\n",
      "Requirement already satisfied: transformers>=4.51 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (4.57.2)\n",
      "Requirement already satisfied: transformers-stream-generator<0.0.6,>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.0.5)\n",
      "Requirement already satisfied: typeguard<5.0,>=4.2 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (4.4.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (4.15.0)\n",
      "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.23.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.23.0->transformer_lens) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.7.1->transformer_lens) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.7.1->transformer_lens) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.7.1->transformer_lens) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.7.1->transformer_lens) (2.32.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.7.1->transformer_lens) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.7.1->transformer_lens) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2025.3.0)\n",
      "Requirement already satisfied: wadler-lindig>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from jaxtyping>=0.2.11->transformer_lens) (0.1.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->transformer_lens) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->transformer_lens) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->transformer_lens) (2025.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.6.0->transformer_lens) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.6.0->transformer_lens) (2.19.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (3.5.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51->transformer_lens) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51->transformer_lens) (0.22.1)\n",
      "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (8.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (3.1.45)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (4.5.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (5.29.5)\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (2.12.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (2.46.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (3.13.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.12)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.23.0->transformer_lens) (1.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->transformer_lens) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.6->transformer_lens) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.6->transformer_lens) (3.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (1.22.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformer_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uaGxnbGv__Y2"
   },
   "outputs": [],
   "source": [
    "!pip install -q torch datasets matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8FGHPFrQq_d"
   },
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YjNXu4s5ACDG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformer_lens import HookedTransformer\n",
    "from datasets import load_dataset\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_roiFe5tAGWt"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrOPtldiQq_f"
   },
   "source": [
    "## 2. Load Model and Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "M9BIYj8FAUBV"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"EleutherAI/pythia-160m-deduped\"\n",
    "FALLBACK_MODEL = \"EleutherAI/pythia-70m-deduped\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE = torch.float16 if torch.cuda.is_available() else torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "referenced_widgets": [
      "ba50c06aceec443c9b7f0152d75fb8a0",
      "c79c33426a4f43e4a461b5833f91857d",
      "967ccafebda24f929f6b685309411c30",
      "f9d8e8728f8d421885b49d7b9717a8bb",
      "c990e7e5d8dc4d92b02b7f698f7eed95",
      "0b38a0816cb34c67aa02ec1e7cec8ea3",
      "fb00da97dd4b49a098c1980b59e51963",
      "ca5d25b2b9b0470a9aee889df9161a9e",
      "c32b6379f77347179fb864d94cb10452",
      "1d93f7e7b4af4125879d8d8ed75b73b0",
      "67c439e6d73b42a49c9a34fe8bb31488",
      "6bc0abcb495d4a3ba167f964a1075f2d",
      "5a6263cb95c64080b8211e2f09b669cd",
      "424e0cc165a84ea993caaaaddf99f1e4",
      "223e25e5160e45418172694020d4dbdd",
      "45cccd3cc3db44448c71df34ae04acd2",
      "986b76aec3634381b46a9f0be992e567",
      "2f794f76659449acbafd0a4a64d13564",
      "5aef4a0fc0f941adbcd74277baf75598",
      "8ad9d7552aea437c82ee326f84b45966",
      "097fa3991ce34fc0b7f82ed225b2ffbd",
      "857e281b870844bc87903c84ef4f53fc",
      "4aa39065d6104bd98980526fb57b703a",
      "57032db6584f4c9cb6e8cc2625d2ba0e",
      "ee57839289834310b8e9bcf64b07bdb0",
      "b9af075bee9c41209e6df2dbad3e6b8c",
      "62d8e7ebb0fe4aa280924b88aef3b097",
      "a8d232e7aa1b4ceda96947512fb6e451",
      "19d049d06ecb4c18a1b3ea5339a97107",
      "64a6600c60c74a69a31c49e9ff390bbe",
      "07ca04750ed84ab5b19fc19e079aa263",
      "0949da29d4194153ba16e83c5a903e4b",
      "ed2d5fa3e2104d15911d65935c9aeaad",
      "eb60622a17ad403aa7dcec24e9f92f71",
      "1d4b4903a2ce4f4ab975fec6ca96b9db",
      "c5cd37a6183e4f9f9d4445112fe86235",
      "5b490c57283b4da3a9a52b97565bb6be",
      "bbccd909305d42ccba85dc9f5f2255e4",
      "62b120f636d24188832d16a24de902ae",
      "ae9ca4627ac44d4abce73e2c7a1244b8",
      "141de40bd1e2470a8930922163771468",
      "92714d892d44474eaa5e60760907154f",
      "cd962bd3dc464771b5ffe51844087562",
      "cab70ff0c0b346af99f6c442c265165c",
      "818263762e564788bce68cd6b0a7179d",
      "414db2d470b84f89b725f59d519d6142",
      "2c41bb31da194ea7921102b58c70d728",
      "9672078500934bcb9fdaee3333305d5d",
      "14b609d8640b491aa5f0c4b67d85c127",
      "81bac74cbcd64ce3adb24a5679d3b5fb",
      "b23739392dbc4145a7f2c647a7d51d12",
      "1166907735a34f7386f83c7d68ad6d26",
      "1626b27865694189905d18634fd6543e",
      "bccda85d67cc42bea051b1d4ecac567d",
      "53f19eae43c344bf9555406367c63994"
     ]
    },
    "id": "styjan6yAW8E",
    "outputId": "06f773f7-da05-4599-d6fe-42a1ac3fe740"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-160m-deduped into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# download the weights of either the main model or the fallback model.\n",
    "\n",
    "try:\n",
    "    model = HookedTransformer.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        device=DEVICE,\n",
    "        dtype=DTYPE,\n",
    "        fold_ln=False,\n",
    "        center_writing_weights=False,\n",
    "        center_unembed=False,\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load {MODEL_NAME}: {e}\")\n",
    "    try:\n",
    "        model = HookedTransformer.from_pretrained(\n",
    "            FALLBACK_MODEL,\n",
    "            device=DEVICE,\n",
    "            dtype=DTYPE,\n",
    "            fold_ln=False,\n",
    "            center_writing_weights=False,\n",
    "            center_unembed=False,\n",
    "        )\n",
    "        MODEL_NAME = FALLBACK_MODEL\n",
    "    except Exception as e2:\n",
    "        print(f\"Failed to load fallback model: {e2}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_eq3mD-qAZuB"
   },
   "outputs": [],
   "source": [
    "tokenizer = model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "e13b9973c0f44cb49f7afff8ffb838af",
      "e6e23cd9d7a8443dae5c915c15edd1e1",
      "5263007ac76b491da9efcf462402b6ed",
      "74b0a671b7cf428f86c9953e0e2bd479",
      "db6f7b111da94389ba277efc5837644d",
      "4ebc962f5567444f84f5700d9c8f22ce",
      "81c8912986c44a5181f38ce2b415680e",
      "394fea529a324f54a8acf105f77dd63a",
      "d7942742b9e04b7fb60ed9f47640066d",
      "bf2bd91adda649b8a8ed3baf537aa082",
      "3baebd7f602f429ca6d4d752e031ffc0",
      "eccc8740a11947e880ec2c9f3e228c32",
      "6dd5f65e4e4b4f8da5d1080c78af2e69",
      "0497dce3d298466fb1f703905b0d9b9f",
      "ce2ad72509294c71bceb5aa4fb8523c1",
      "5a812a53fa2f4ccf99688106713a7365",
      "a36f48a76cc74e78af6d9b34f1b8e8e0",
      "f9629157c486459e8638364be21e1062",
      "900df02c41034ba599ef8d6eeaf0a2b3",
      "fbf56ae82d83437c8c957ed3167ba3d1",
      "ccc3d70a4c33447e98c4ed9ca2262aad",
      "ce130214befe4cbdb040766ce1de8b9f",
      "c218e31d99354731bd3082795527339d",
      "7e6de1d18be047ed98c97dcdfc859893",
      "91be3743e6344839907ff04560db747e",
      "8e52e26b140246f78e7115e38e624939",
      "daa6cf22a25b4ed5b4b8754f9d6bdcf9",
      "c8a359eb0d0a468998d9be882eac9799",
      "daf15993cdd04197a5fe9080b18fbefb",
      "87e8a7fb81af42f4917d0a0a9f9e98aa",
      "a1714a1405254ae0b7537ad70a241288",
      "a39bf2ae5401455b8752207c7ce2af85",
      "f00fdaf15c0f45cfbcb177d3b198d053",
      "5b5a731ed11b443bb62a026016e0a7a7",
      "55507e2c8c8b4a90935c3ab61025eb06",
      "da2f66684d9449b09fe9618fcc16dd54",
      "33a0cc2a7f2d4747b16bc1dbb0397f80",
      "f7a1c984b0294475822d46b5cbada9ad",
      "a7c4cdb042f24a51a5d20beb9e3d48c5",
      "f121b9b387eb4d3f810864ed92546592",
      "b728614dd13543a1a5afeb701ca88964",
      "5856d969323d47aea89558ccf29b31e3",
      "46d2f0a648724385901e6f04624f9816",
      "c0ceeb9fa80a4a33811928569f8d5d65",
      "5dd7e96522f54ae38c37c8d7f861c4cd",
      "4664c7a5cdbd48358393201fcb0af2b1",
      "1069c91448d64b40a1c527250e6d1209",
      "92065407c01a4af5b102bc482f754817",
      "768bceb518db4cfe91ab789cb8f4fddf",
      "6d685d60ece1499f8da8da5aefc4211d",
      "07e762c14dec446687c366facda6a501",
      "edc0ffa49b6b4c97a0c1c356103879fd",
      "37e29a62c1bb4eea8d743acd0a742633",
      "203c4390878d4e3a9d5b7a1f1a1cd75c",
      "15a2204175274d5b845fdca563940ec2",
      "45bf1be2be6340dca1d625cc99e5bcc0",
      "c292cce28edd48598bd1eda64faeb16c",
      "96148989609c4deab30351e2af95af9b",
      "bb08ce40d7f04c458471c2daf6afe3bb",
      "dea237f9a15c4bf8ad813dd9d34754b4",
      "e55261c9dd624b3ba3448b0032e97e09",
      "bc8adfc5bfed447ab6ec54c8df94fb3a",
      "a30f97e53dab4e65a82aaa9cc7dd3d77",
      "d816f35c433a41b1849c8f073d7a61fe",
      "26d7e97f442c439186214ec992af3f59",
      "7eb1181ddad54bd9b3daddf63ee335b0",
      "325cd522b8d54e08bc7cb2aee108a92e",
      "d04434f5b8dc4a12bdd2e3abdbd12f64",
      "4ef3a4469f954e51a3127f7bf230f14f",
      "1e55eb20ea624463b3240df522c0e1da",
      "7387a8a528f04ac8bef73f7deca12940",
      "a058d403484b46dba68a115c0e4948a5",
      "649322832a0f49d091a9d473238de51c",
      "97efd9e78e29458ebb2282c3ad39b788",
      "7e634fa402d14aecb5bd9e319e91f90c",
      "c770fd9b9e12452d8e46b47e9a9e2644",
      "3e3fde0b189d4cfa859d1fea352831dd"
     ]
    },
    "id": "egrbluNoAo5o",
    "outputId": "d78f081a-ff97-4b8b-c756-b0a7073210ed"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"glue\", \"sst2\", split=\"validation\")\n",
    "\n",
    "N_PROMPTS = 200\n",
    "clean_prompts = [\n",
    "    f\"Review: {dataset[i]['sentence']}\\nSentiment:\"\n",
    "    for i in range(min(N_PROMPTS, len(dataset)))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n69xorTSQq_j"
   },
   "source": [
    "## 3. Generate Adversarial Triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5RShVgQIDWC0"
   },
   "outputs": [],
   "source": [
    "labels = [dataset[i]['label'] for i in range(len(clean_prompts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dl3WevSVAsbJ"
   },
   "outputs": [],
   "source": [
    "def build_candidate_token_list(model, n_tokens=100):\n",
    "    \"\"\"Build a diverse list of candidate tokens that decode to actual words.\"\"\"\n",
    "    special_token_ids = {0}  # Token 0 is <|endoftext|>\n",
    "    if hasattr(model.tokenizer, 'all_special_ids'):\n",
    "        special_token_ids.update(model.tokenizer.all_special_ids)\n",
    "\n",
    "    # Sample from vocabulary ranges where actual words are more likely\n",
    "    # Use smaller steps to get more diverse tokens\n",
    "    ranges_to_check = [\n",
    "        (1000, 5000, 20),\n",
    "        (5000, 15000, 10),\n",
    "        (15000, 30000, 5),\n",
    "        (30000, 45000, 3),\n",
    "    ]\n",
    "\n",
    "    good_tokens = []\n",
    "    for vocab_start, vocab_end, step in ranges_to_check:\n",
    "        for token_id in range(vocab_start, min(vocab_end, model.cfg.d_vocab), step):\n",
    "            if token_id in special_token_ids:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                token_str = model.to_string(torch.tensor([token_id]))\n",
    "                # Filter: must contain alphanumeric characters, not special tokens\n",
    "                if (token_str and\n",
    "                    len(token_str.strip()) > 0 and\n",
    "                    not token_str.startswith('<|') and\n",
    "                    not token_str.startswith('[') and\n",
    "                    len(token_str) < 15 and\n",
    "                    any(c.isalnum() for c in token_str)):\n",
    "                    good_tokens.append(token_id)\n",
    "                    if len(good_tokens) >= n_tokens:\n",
    "                        return good_tokens\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    return good_tokens[:n_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HFJwD6UZAumP"
   },
   "outputs": [],
   "source": [
    "def get_label_token_ids(model):\n",
    "    \"\"\"Get token IDs for 'negative' and 'positive' labels.\"\"\"\n",
    "    label_tokens = {}\n",
    "    for label_val, label_name in [(0, \"negative\"), (1, \"positive\")]:\n",
    "        try:\n",
    "            token_id = model.to_single_token(f\" {label_name}\")\n",
    "            label_tokens[label_val] = token_id\n",
    "        except:\n",
    "            try:\n",
    "                token_id = model.to_single_token(label_name)\n",
    "                label_tokens[label_val] = token_id\n",
    "            except:\n",
    "                tokens = model.tokenizer.encode(f\" {label_name}\", add_special_tokens=False)\n",
    "                if tokens:\n",
    "                    label_tokens[label_val] = tokens[0]\n",
    "    return label_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VgRpVbE7BgIW"
   },
   "outputs": [],
   "source": [
    "def insert_trigger(prompt, trigger_tokens):\n",
    "    \"\"\"Insert trigger tokens after 'Sentiment:' in the prompt.\"\"\"\n",
    "    parts = prompt.split()\n",
    "\n",
    "    try:\n",
    "        sentiment_idx = next(\n",
    "            i for i, tok in enumerate(parts)\n",
    "            if tok.startswith(\"Sentiment\")\n",
    "        )\n",
    "    except StopIteration:\n",
    "        sentiment_idx = 0  # fallback when no prefix is found\n",
    "\n",
    "    insert_position = sentiment_idx + 1\n",
    "    adv_parts = parts[:insert_position] + trigger_tokens + parts[insert_position:]\n",
    "    return \" \".join(adv_parts)\n",
    "\n",
    "\n",
    "def evaluate_candidates_batched(model, base_tokens, position, candidate_tokens, correct_label_token, batch_size=32):\n",
    "    \"\"\"Evaluate multiple candidate tokens in a batched forward pass.\"\"\"\n",
    "\n",
    "    valid_candidates = [t for t in candidate_tokens if t != 0]\n",
    "    if not valid_candidates:\n",
    "        return []\n",
    "\n",
    "    objectives = []\n",
    "    device = base_tokens.device\n",
    "    dtype = base_tokens.dtype\n",
    "\n",
    "    # Process candidates in batches\n",
    "    for i in range(0, len(valid_candidates), batch_size):\n",
    "        batch_candidates = valid_candidates[i:i+batch_size]\n",
    "\n",
    "        batch_sequences = []\n",
    "        for token_id in batch_candidates:\n",
    "            modified = torch.cat([\n",
    "                base_tokens[:position],\n",
    "                torch.tensor([token_id], device=device, dtype=dtype),\n",
    "                base_tokens[position:]\n",
    "            ])\n",
    "            batch_sequences.append(modified)\n",
    "\n",
    "        # Stack into batch tensor (all sequences have same length)\n",
    "        batch_tensor = torch.stack(batch_sequences)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(batch_tensor)\n",
    "\n",
    "            next_token_logits = logits[:, -1, :]  # [batch, vocab]\n",
    "            next_token_probs = torch.softmax(next_token_logits, dim=-1)\n",
    "\n",
    "            # Objective: negative log-prob of correct label\n",
    "            adv_probs = next_token_probs[:, correct_label_token]\n",
    "            batch_objectives = -torch.log(adv_probs + 1e-10)\n",
    "            objectives.extend(batch_objectives.cpu().tolist())\n",
    "\n",
    "    return objectives\n",
    "\n",
    "\n",
    "def generate_adv_prompt(model, prompt, label, candidate_tokens, positions, label_tokens, batch_size=32):\n",
    "    \"\"\"Generate adversarial prompt by inserting 1-3 tokens using iterative greedy approach.\"\"\"\n",
    "    tokens = model.to_tokens(prompt)[0]\n",
    "    seq_len = tokens.shape[0]\n",
    "\n",
    "    if label not in label_tokens:\n",
    "        return prompt, 0, 0, [], []\n",
    "\n",
    "    correct_label_token = label_tokens[label]\n",
    "\n",
    "    # Get baseline probability of correct label\n",
    "    with torch.no_grad():\n",
    "        logits = model(tokens.unsqueeze(0))\n",
    "        next_token_logits = logits[0, -1, :]\n",
    "        next_token_probs = torch.softmax(next_token_logits, dim=-1)\n",
    "        baseline_prob = next_token_probs[correct_label_token].item()\n",
    "\n",
    "    # Filter positions to valid range\n",
    "    valid_positions = [p for p in positions if 0 < p < seq_len]\n",
    "    if not valid_positions:\n",
    "        return prompt, 0, 0, [], []\n",
    "\n",
    "    # find best 1-token insertion\n",
    "    best_1_token = None\n",
    "    best_1_position = None\n",
    "    best_1_objective = float('-inf')\n",
    "\n",
    "    for pos in valid_positions:\n",
    "        objectives = evaluate_candidates_batched(\n",
    "            model, tokens, pos, candidate_tokens, correct_label_token, batch_size\n",
    "        )\n",
    "        valid_candidates = [t for t in candidate_tokens if t != 0]\n",
    "\n",
    "        for idx, objective in enumerate(objectives):\n",
    "            if objective > best_1_objective:\n",
    "                best_1_objective = objective\n",
    "                best_1_token = valid_candidates[idx]\n",
    "                best_1_position = pos\n",
    "\n",
    "    # If no improvement found, return original\n",
    "    if best_1_token is None or best_1_position is None:\n",
    "        return prompt, 0, 0, [], [], {\"k1\": None, \"k2\": None, \"k3\": None}, {\"r2\": None, \"r3\": None}, []\n",
    "\n",
    "    # Build 1-token result\n",
    "    tokens_1 = torch.cat([\n",
    "        tokens[:best_1_position],\n",
    "        torch.tensor([best_1_token], device=tokens.device, dtype=tokens.dtype),\n",
    "        tokens[best_1_position:]\n",
    "    ])\n",
    "\n",
    "    # re-evaluate objective\n",
    "    with torch.no_grad():\n",
    "        logits_1 = model(tokens_1.unsqueeze(0))\n",
    "        next_token_logits_1 = logits_1[0, -1, :]\n",
    "        next_token_probs_1 = torch.softmax(next_token_logits_1, dim=-1)\n",
    "        objective_1_actual = -np.log(next_token_probs_1[correct_label_token].item() + 1e-10)\n",
    "\n",
    "    result_1 = {\n",
    "        'tokens': tokens_1,\n",
    "        'objective': objective_1_actual,\n",
    "        'num_tokens': 1,\n",
    "        'inserted_tokens': [best_1_token],\n",
    "        'positions': [best_1_position]\n",
    "    }\n",
    "\n",
    "    best_result = result_1\n",
    "\n",
    "    # try adding 2nd token\n",
    "    # test positions around 1st token\n",
    "    pos_1 = best_1_position\n",
    "    candidate_positions_2 = []\n",
    "    if pos_1 > 0:\n",
    "        candidate_positions_2.append(pos_1 - 1)  # Before\n",
    "    candidate_positions_2.append(pos_1)  # At same position (creates sequence)\n",
    "    if pos_1 < tokens_1.shape[0] - 1:\n",
    "        candidate_positions_2.append(pos_1 + 1)  # After\n",
    "    candidate_positions_2.append(pos_1 + 2)  # After the inserted token\n",
    "\n",
    "    # Filter to valid positions\n",
    "    candidate_positions_2 = [p for p in candidate_positions_2 if 0 < p < tokens_1.shape[0]]\n",
    "\n",
    "    # Initialize to actual 1-token objective for fair comparison\n",
    "    best_2_objective = objective_1_actual\n",
    "    best_2_token = None\n",
    "    best_2_position = None\n",
    "\n",
    "    for pos_2 in candidate_positions_2:\n",
    "        objectives = evaluate_candidates_batched(\n",
    "            model, tokens_1, pos_2, candidate_tokens, correct_label_token, batch_size\n",
    "        )\n",
    "        valid_candidates = [t for t in candidate_tokens if t != 0]\n",
    "\n",
    "        for idx, objective in enumerate(objectives):\n",
    "            # update if better\n",
    "            if objective > best_2_objective + 1e-6:\n",
    "                best_2_objective = objective\n",
    "                best_2_token = valid_candidates[idx]\n",
    "                best_2_position = pos_2\n",
    "\n",
    "    # compare with threshold\n",
    "    if best_2_token is not None and best_2_position is not None and best_2_objective > objective_1_actual + 1e-6:\n",
    "        tokens_2 = torch.cat([\n",
    "            tokens_1[:best_2_position],\n",
    "            torch.tensor([best_2_token], device=tokens.device, dtype=tokens.dtype),\n",
    "            tokens_1[best_2_position:]\n",
    "        ])\n",
    "\n",
    "        # re-evaluate objective\n",
    "        with torch.no_grad():\n",
    "            logits_2 = model(tokens_2.unsqueeze(0))\n",
    "            next_token_logits_2 = logits_2[0, -1, :]\n",
    "            next_token_probs_2 = torch.softmax(next_token_logits_2, dim=-1)\n",
    "            objective_2_actual = -np.log(next_token_probs_2[correct_label_token].item() + 1e-10)\n",
    "\n",
    "        result_2 = {\n",
    "            'tokens': tokens_2,\n",
    "            'objective': objective_2_actual,\n",
    "            'num_tokens': 2,\n",
    "            'inserted_tokens': [best_1_token, best_2_token],\n",
    "            'positions': [best_1_position, best_2_position]\n",
    "        }\n",
    "        best_result = result_2\n",
    "\n",
    "        # try adding 3rd token\n",
    "        pos_2 = best_2_position\n",
    "        candidate_positions_3 = []\n",
    "        if pos_2 > 0:\n",
    "            candidate_positions_3.append(pos_2 - 1)\n",
    "        candidate_positions_3.append(pos_2)\n",
    "        if pos_2 < tokens_2.shape[0] - 1:\n",
    "            candidate_positions_3.append(pos_2 + 1)\n",
    "        candidate_positions_3.append(pos_2 + 2)\n",
    "\n",
    "        candidate_positions_3 = [p for p in candidate_positions_3 if 0 < p < tokens_2.shape[0]]\n",
    "\n",
    "        # Initialize to actual 2-token objective for fair comparison\n",
    "        best_3_objective = objective_2_actual\n",
    "        best_3_token = None\n",
    "        best_3_position = None\n",
    "\n",
    "        for pos_3 in candidate_positions_3:\n",
    "            objectives = evaluate_candidates_batched(\n",
    "                model, tokens_2, pos_3, candidate_tokens, correct_label_token, batch_size\n",
    "            )\n",
    "            valid_candidates = [t for t in candidate_tokens if t != 0]\n",
    "\n",
    "            for idx, objective in enumerate(objectives):\n",
    "                # update if better\n",
    "                if objective > best_3_objective + 1e-6:\n",
    "                    best_3_objective = objective\n",
    "                    best_3_token = valid_candidates[idx]\n",
    "                    best_3_position = pos_3\n",
    "\n",
    "        # compare with threshold\n",
    "        if best_3_token is not None and best_3_position is not None and best_3_objective > objective_2_actual + 1e-6:\n",
    "            tokens_3 = torch.cat([\n",
    "                tokens_2[:best_3_position],\n",
    "                torch.tensor([best_3_token], device=tokens.device, dtype=tokens.dtype),\n",
    "                tokens_2[best_3_position:]\n",
    "            ])\n",
    "\n",
    "            # re-evaluate objective\n",
    "            with torch.no_grad():\n",
    "                logits_3 = model(tokens_3.unsqueeze(0))\n",
    "                next_token_logits_3 = logits_3[0, -1, :]\n",
    "                next_token_probs_3 = torch.softmax(next_token_logits_3, dim=-1)\n",
    "                objective_3_actual = -np.log(next_token_probs_3[correct_label_token].item() + 1e-10)\n",
    "\n",
    "            result_3 = {\n",
    "                'tokens': tokens_3,\n",
    "                'objective': objective_3_actual,\n",
    "                'num_tokens': 3,\n",
    "                'inserted_tokens': [best_1_token, best_2_token, best_3_token],\n",
    "                'positions': [best_1_position, best_2_position, best_3_position]\n",
    "            }\n",
    "            best_result = result_3\n",
    "\n",
    "    # Convert inserted tokens to strings and insert after \"Sentiment:\"\n",
    "    inserted_token_strings = [model.to_string(torch.tensor([tid])) for tid in best_result['inserted_tokens']]\n",
    "    adv_prompt = insert_trigger(prompt, inserted_token_strings)\n",
    "\n",
    "    trigger_pos = best_result['positions'][0] + 1 if best_result['positions'] else 0\n",
    "\n",
    "    # Build objective_k dict\n",
    "    objective_k = {\n",
    "        \"k1\": objective_1_actual if 'objective_1_actual' in locals() else None,\n",
    "        \"k2\": objective_2_actual if 'objective_2_actual' in locals() else None,\n",
    "        \"k3\": objective_3_actual if 'objective_3_actual' in locals() else None\n",
    "    }\n",
    "\n",
    "    # Compute relative improvements\n",
    "    relative_improvements = {\"r2\": None, \"r3\": None}\n",
    "    if objective_k[\"k1\"] is not None and objective_k[\"k2\"] is not None and objective_k[\"k1\"] > 0:\n",
    "        relative_improvements[\"r2\"] = (objective_k[\"k2\"] - objective_k[\"k1\"]) / objective_k[\"k1\"]\n",
    "    if objective_k[\"k2\"] is not None and objective_k[\"k3\"] is not None and objective_k[\"k2\"] > 0:\n",
    "        relative_improvements[\"r3\"] = (objective_k[\"k3\"] - objective_k[\"k2\"]) / objective_k[\"k2\"]\n",
    "\n",
    "    # Compute ablation marginals\n",
    "    ablation_marginals = []\n",
    "    if best_result['num_tokens'] == 3 and 'tokens_3' in locals():\n",
    "        # For 3-token: ablate each token individually\n",
    "        inserted_tokens = best_result['inserted_tokens']\n",
    "        insertion_positions = best_result['positions']\n",
    "        baseline_obj = objective_k[\"k3\"]\n",
    "\n",
    "        # Sort positions to handle insertions in order\n",
    "        sorted_indices = sorted(range(3), key=lambda i: insertion_positions[i])\n",
    "\n",
    "        for i in range(3):\n",
    "            # Build sequence without token i\n",
    "            tokens_ablated = tokens.clone()\n",
    "            for idx in sorted_indices:\n",
    "                if idx != i:\n",
    "                    tok = inserted_tokens[idx]\n",
    "                    pos = insertion_positions[idx]\n",
    "                    # adjust position for previous insertions\n",
    "                    offset = sum(1 for j in sorted_indices if j < idx and j != i and insertion_positions[j] <= pos)\n",
    "                    insert_pos = pos + offset\n",
    "                    tokens_ablated = torch.cat([\n",
    "                        tokens_ablated[:insert_pos],\n",
    "                        torch.tensor([tok], device=tokens.device, dtype=tokens.dtype),\n",
    "                        tokens_ablated[insert_pos:]\n",
    "                    ])\n",
    "\n",
    "            # Evaluate ablated sequence\n",
    "            with torch.no_grad():\n",
    "                logits_ablated = model(tokens_ablated.unsqueeze(0))\n",
    "                next_token_logits_ablated = logits_ablated[0, -1, :]\n",
    "                next_token_probs_ablated = torch.softmax(next_token_logits_ablated, dim=-1)\n",
    "                objective_ablated = -np.log(next_token_probs_ablated[correct_label_token].item() + 1e-10)\n",
    "\n",
    "            # compute marginal\n",
    "            if baseline_obj is not None and baseline_obj > 1e-10:\n",
    "                marginal = (objective_ablated - baseline_obj) / baseline_obj\n",
    "            else:\n",
    "                marginal = 0.0\n",
    "            ablation_marginals.append(marginal)\n",
    "    elif best_result['num_tokens'] == 2:\n",
    "        # For 2-token: marginal of 2nd token relative to 1-token baseline\n",
    "        if objective_k[\"k1\"] is not None and objective_k[\"k2\"] is not None and objective_k[\"k1\"] > 1e-10:\n",
    "            marginal_2 = (objective_k[\"k2\"] - objective_k[\"k1\"]) / objective_k[\"k1\"]\n",
    "            ablation_marginals = [0.0, marginal_2]\n",
    "        else:\n",
    "            ablation_marginals = [0.0, 0.0]\n",
    "    elif best_result['num_tokens'] == 1:\n",
    "        ablation_marginals = [0.0]\n",
    "\n",
    "    return (\n",
    "        adv_prompt,\n",
    "        trigger_pos,\n",
    "        best_result['num_tokens'],\n",
    "        best_result['inserted_tokens'],\n",
    "        best_result['positions'],\n",
    "        objective_k,\n",
    "        relative_improvements,\n",
    "        ablation_marginals\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8aIb2ZAABhI9"
   },
   "outputs": [],
   "source": [
    "def generate_all_adv_prompts(model, clean_prompts, labels, n_candidates=500, batch_size=32, artifacts_dir=\"artifacts\"):\n",
    "    \"\"\"Generate adversarial prompts for all clean prompts using iterative greedy 1-3 token insertion.\"\"\"\n",
    "    import json\n",
    "    import os\n",
    "\n",
    "    # Create artifacts directory if it doesn't exist\n",
    "    os.makedirs(artifacts_dir, exist_ok=True)\n",
    "\n",
    "    label_tokens = get_label_token_ids(model)\n",
    "\n",
    "    # build candidate token list once and reuse for all prompts\n",
    "    candidate_tokens = build_candidate_token_list(model, n_candidates)\n",
    "\n",
    "    if not candidate_tokens:\n",
    "        raise ValueError(\"Failed to build candidate token list\")\n",
    "\n",
    "    adv_prompts = []\n",
    "    trigger_positions = []\n",
    "    metadata_list = []\n",
    "\n",
    "    metadata_file = os.path.join(artifacts_dir, \"adv_metadata.jsonl\")\n",
    "    # Clear existing file\n",
    "    if os.path.exists(metadata_file):\n",
    "        os.remove(metadata_file)\n",
    "\n",
    "    for i, (prompt, label) in enumerate(zip(clean_prompts, labels)):\n",
    "        tokens = model.to_tokens(prompt)[0]\n",
    "        seq_len = tokens.shape[0]\n",
    "\n",
    "        # calculate max insertion position\n",
    "        review_text = prompt.split(\"\\nSentiment:\")[0]\n",
    "        review_tokens = model.to_tokens(review_text)[0]\n",
    "        max_insertion_pos = review_tokens.shape[0] - 1\n",
    "\n",
    "        # check minimum tokens\n",
    "        if max_insertion_pos < 2:\n",
    "            adv_prompts.append(prompt)\n",
    "            trigger_positions.append(0)\n",
    "            metadata_entry = {\n",
    "                \"id\": i,\n",
    "                \"clean_prompt\": prompt,\n",
    "                \"clean_label\": int(label),\n",
    "                \"adv_tokens\": [],\n",
    "                \"adv_decoded\": \"\",\n",
    "                \"positions\": [],\n",
    "                \"objective_k\": {\"k1\": None, \"k2\": None, \"k3\": None},\n",
    "                \"relative_improvements\": {\"r2\": None, \"r3\": None},\n",
    "                \"ablation_marginals\": [],\n",
    "                \"chosen_k\": 0\n",
    "            }\n",
    "            metadata_list.append(metadata_entry)\n",
    "            continue\n",
    "\n",
    "        # determine insertion positions\n",
    "        positions = []\n",
    "        if max_insertion_pos > 1:\n",
    "            positions.append(1)\n",
    "        if max_insertion_pos > 3:\n",
    "            positions.append(min(max_insertion_pos // 2, max_insertion_pos - 1))\n",
    "        if max_insertion_pos > 2:\n",
    "            positions.append(max_insertion_pos)\n",
    "        positions = sorted(set([p for p in positions if 0 < p <= max_insertion_pos]))[:3]\n",
    "\n",
    "        if not positions:\n",
    "            adv_prompts.append(prompt)\n",
    "            trigger_positions.append(0)\n",
    "            metadata_entry = {\n",
    "                \"id\": i,\n",
    "                \"clean_prompt\": prompt,\n",
    "                \"clean_label\": int(label),\n",
    "                \"adv_tokens\": [],\n",
    "                \"adv_decoded\": \"\",\n",
    "                \"positions\": [],\n",
    "                \"objective_k\": {\"k1\": None, \"k2\": None, \"k3\": None},\n",
    "                \"relative_improvements\": {\"r2\": None, \"r3\": None},\n",
    "                \"ablation_marginals\": [],\n",
    "                \"chosen_k\": 0\n",
    "            }\n",
    "            metadata_list.append(metadata_entry)\n",
    "            continue\n",
    "\n",
    "        # generate adversarial prompt\n",
    "        result = generate_adv_prompt(\n",
    "            model, prompt, label, candidate_tokens, positions, label_tokens, batch_size\n",
    "        )\n",
    "        adv_prompt, trigger_pos, num_tokens, inserted_tokens, insertion_positions, objective_k, relative_improvements, ablation_marginals = result\n",
    "\n",
    "        # Decode inserted tokens\n",
    "        adv_decoded = \" \".join([model.to_string(torch.tensor([tid])) for tid in inserted_tokens])\n",
    "\n",
    "        # Build metadata entry\n",
    "        metadata_entry = {\n",
    "            \"id\": i,\n",
    "            \"clean_prompt\": prompt,\n",
    "            \"clean_label\": int(label),\n",
    "            \"adv_tokens\": [int(tid) for tid in inserted_tokens],\n",
    "            \"adv_decoded\": adv_decoded,\n",
    "            \"positions\": [int(pos) for pos in insertion_positions],\n",
    "            \"objective_k\": {\n",
    "                \"k1\": float(objective_k[\"k1\"]) if objective_k[\"k1\"] is not None else None,\n",
    "                \"k2\": float(objective_k[\"k2\"]) if objective_k[\"k2\"] is not None else None,\n",
    "                \"k3\": float(objective_k[\"k3\"]) if objective_k[\"k3\"] is not None else None\n",
    "            },\n",
    "            \"relative_improvements\": {\n",
    "                \"r2\": float(relative_improvements[\"r2\"]) if relative_improvements[\"r2\"] is not None else None,\n",
    "                \"r3\": float(relative_improvements[\"r3\"]) if relative_improvements[\"r3\"] is not None else None\n",
    "            },\n",
    "            \"ablation_marginals\": [float(m) for m in ablation_marginals],\n",
    "            \"chosen_k\": int(num_tokens)\n",
    "        }\n",
    "\n",
    "        # Save to JSONL immediately (append mode)\n",
    "        with open(metadata_file, 'a') as f:\n",
    "            f.write(json.dumps(metadata_entry) + '\\n')\n",
    "\n",
    "        adv_prompts.append(adv_prompt)\n",
    "        trigger_positions.append(trigger_pos)\n",
    "        metadata_list.append(metadata_entry)\n",
    "\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"  Processed {i + 1}/{len(clean_prompts)} prompts\")\n",
    "\n",
    "    # build metadata dict\n",
    "    metadata = {\n",
    "        'num_tokens': [m['chosen_k'] for m in metadata_list],\n",
    "        'inserted_tokens': [m['adv_tokens'] for m in metadata_list],\n",
    "        'insertion_positions': [m['positions'] for m in metadata_list],\n",
    "        'full_metadata': metadata_list\n",
    "    }\n",
    "\n",
    "    return adv_prompts, trigger_positions, metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rBpsi_E9Bjpe",
    "outputId": "cf8edb9b-b6d3-4961-ec10-3bf8aa5d6413"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Processed 50/200 prompts\n",
      "  Processed 100/200 prompts\n",
      "  Processed 150/200 prompts\n",
      "  Processed 200/200 prompts\n"
     ]
    }
   ],
   "source": [
    "adv_prompts, trigger_positions, metadata = generate_all_adv_prompts(\n",
    "    model, clean_prompts, labels, n_candidates=500, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uBb6n4EqQq_o"
   },
   "outputs": [],
   "source": [
    "# Save clean and adversarial prompts to artifacts/\n",
    "import os\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "\n",
    "with open(\"artifacts/clean_prompts.txt\", \"w\") as f:\n",
    "    for prompt in clean_prompts:\n",
    "        f.write(prompt + \"\\n\")\n",
    "\n",
    "with open(\"artifacts/adv_prompts.txt\", \"w\") as f:\n",
    "    for prompt in adv_prompts:\n",
    "        f.write(prompt + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BADckAk5Qq_o"
   },
   "source": [
    "## 4. Extract Clean and Adversarial Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "SXA6v_BQQq_o"
   },
   "outputs": [],
   "source": [
    "def extract_activations(model, prompts, hook_points=None, batch_size=16):\n",
    "    \"\"\"Extract activations for a list of prompts.\"\"\"\n",
    "    if hook_points is None:\n",
    "        # default hook points\n",
    "        hook_points = []\n",
    "        for l in range(model.cfg.n_layers):\n",
    "            hook_points.append(f\"blocks.{l}.hook_mlp_out\")\n",
    "            hook_points.append(f\"blocks.{l}.attn.hook_z\")\n",
    "\n",
    "    activations = {hook: [] for hook in hook_points}\n",
    "\n",
    "    # find max sequence length\n",
    "    max_seq_len = 0\n",
    "    for prompt in prompts:\n",
    "        tokens = model.to_tokens(prompt)\n",
    "        max_seq_len = max(max_seq_len, tokens.shape[1])\n",
    "\n",
    "    for i in range(0, len(prompts), batch_size):\n",
    "        batch_prompts = prompts[i:i+batch_size]\n",
    "        batch_tokens = model.to_tokens(batch_prompts)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, cache = model.run_with_cache(batch_tokens)\n",
    "\n",
    "        # extract and pad activations\n",
    "        for hook in hook_points:\n",
    "            if hook in cache:\n",
    "                # cache[hook] shape: [batch, seq_len, ...]\n",
    "                hook_acts = cache[hook].cpu()\n",
    "                batch_size_actual, seq_len = hook_acts.shape[0], hook_acts.shape[1]\n",
    "\n",
    "                # pad if needed\n",
    "                if seq_len < max_seq_len:\n",
    "                    pad_shape = list(hook_acts.shape)\n",
    "                    pad_shape[1] = max_seq_len - seq_len\n",
    "                    padding = torch.zeros(pad_shape, dtype=hook_acts.dtype, device=hook_acts.device)\n",
    "                    hook_acts = torch.cat([hook_acts, padding], dim=1)\n",
    "\n",
    "                activations[hook].append(hook_acts)\n",
    "\n",
    "    # concatenate batches\n",
    "    for hook in hook_points:\n",
    "        if activations[hook]:\n",
    "            activations[hook] = torch.cat(activations[hook], dim=0)\n",
    "        else:\n",
    "            activations[hook] = None\n",
    "\n",
    "    return activations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtonsE7HQq_p"
   },
   "source": [
    "## 5. Compute |\u0394norm| and Rank Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "bJQa0tmqQq_p"
   },
   "outputs": [],
   "source": [
    "# Extract activations for clean and adversarial prompts\n",
    "activations_clean = extract_activations(model, clean_prompts, batch_size=16)\n",
    "activations_adv = extract_activations(model, adv_prompts, batch_size=16)\n",
    "\n",
    "# Save activations\n",
    "torch.save(activations_clean, \"artifacts/activations_clean.pt\")\n",
    "torch.save(activations_adv, \"artifacts/activations_adv.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohf3HAYOQq_p"
   },
   "source": [
    "## 6. Causal Patching Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LCh4YvdFQq_p"
   },
   "outputs": [],
   "source": [
    "def compute_delta_metrics(activations_clean, activations_adv, trigger_positions, metadata, model):\n",
    "    \"\"\"Compute \u0394activation and \u0394norm for all components.\"\"\"\n",
    "    components = []\n",
    "    eps = 1e-10\n",
    "\n",
    "    # Get hook points\n",
    "    hook_points = [h for h in activations_clean.keys() if h is not None]\n",
    "\n",
    "    for hook in hook_points:\n",
    "        if hook not in activations_adv or activations_clean[hook] is None:\n",
    "            continue\n",
    "\n",
    "        clean_acts = activations_clean[hook]  # [n_prompts, seq_len, ...]\n",
    "        adv_acts = activations_adv[hook]  # [n_prompts, seq_len, ...]\n",
    "\n",
    "        # parse layer and type\n",
    "        parts = hook.split(\".\")\n",
    "        layer = int(parts[1])\n",
    "\n",
    "        if \"mlp\" in hook:\n",
    "            comp_type = \"mlp\"\n",
    "            # MLP: [batch, seq_len, d_model]\n",
    "            n_components = clean_acts.shape[-1]\n",
    "        elif \"attn\" in hook and \"hook_z\" in hook:\n",
    "            comp_type = \"attn\"\n",
    "            # Attention: [batch, seq_len, n_heads, d_head]\n",
    "            n_components = clean_acts.shape[2]  # n_heads\n",
    "            # average over d_head\n",
    "            clean_acts = clean_acts.mean(dim=-1)  # [batch, seq_len, n_heads]\n",
    "            adv_acts = adv_acts.mean(dim=-1)  # [batch, seq_len, n_heads]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # compute delta at trigger positions\n",
    "        for comp_idx in range(n_components):\n",
    "            clean_comp = clean_acts[:, :, comp_idx]  # [n_prompts, seq_len]\n",
    "            adv_comp = adv_acts[:, :, comp_idx]  # [n_prompts, seq_len]\n",
    "\n",
    "            # get trigger positions\n",
    "            trigger_pos_list = []\n",
    "            for i, (trigger_pos, insertion_positions) in enumerate(zip(trigger_positions, metadata['insertion_positions'])):\n",
    "                if trigger_pos > 0:\n",
    "                    if insertion_positions:\n",
    "                        trigger_pos_list.append(insertion_positions[0])\n",
    "                    else:\n",
    "                        trigger_pos_list.append(trigger_pos - 1)\n",
    "                else:\n",
    "                    trigger_pos_list.append(None)\n",
    "\n",
    "            # compute mean at trigger positions\n",
    "            clean_trigger_vals = []\n",
    "            adv_trigger_vals = []\n",
    "            clean_all_vals = []\n",
    "\n",
    "            for i, (clean_seq, adv_seq, trigger_pos) in enumerate(zip(clean_comp, adv_comp, trigger_pos_list)):\n",
    "                if trigger_pos is not None and trigger_pos < clean_seq.shape[0]:\n",
    "                    clean_trigger_vals.append(clean_seq[trigger_pos].item())\n",
    "                    adv_trigger_vals.append(adv_seq[trigger_pos].item())\n",
    "                # collect all positions for std\n",
    "                clean_all_vals.extend(clean_seq.cpu().tolist())\n",
    "\n",
    "            if not clean_trigger_vals:\n",
    "                continue\n",
    "            mean_clean_trigger = np.mean(clean_trigger_vals)\n",
    "            mean_adv_trigger = np.mean(adv_trigger_vals)\n",
    "            std_clean_all = np.std(clean_all_vals) if clean_all_vals else eps\n",
    "\n",
    "            delta = mean_adv_trigger - mean_clean_trigger\n",
    "            delta_norm = delta / (std_clean_all + eps)\n",
    "\n",
    "            components.append({\n",
    "                'layer': layer,\n",
    "                'type': comp_type,\n",
    "                'index': comp_idx,\n",
    "                'delta': delta,\n",
    "                'delta_norm': delta_norm,\n",
    "                'position': 'trigger'\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(components)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "RVHEtN2eQq_q"
   },
   "outputs": [],
   "source": [
    "# Compute delta metrics and rank components\n",
    "panic_components_df = compute_delta_metrics(\n",
    "    activations_clean, activations_adv, trigger_positions, metadata, model\n",
    ")\n",
    "\n",
    "# Rank by absolute delta_norm\n",
    "panic_components_df['abs_delta_norm'] = panic_components_df['delta_norm'].abs()\n",
    "panic_components_df = panic_components_df.sort_values('abs_delta_norm', ascending=False)\n",
    "\n",
    "# Save to CSV\n",
    "panic_components_df.to_csv(\"artifacts/panic_components.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6v08CPpnQq_q"
   },
   "source": [
    "## 7. Save All Figures and CSV Outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GKMcJzM6Qq_r"
   },
   "outputs": [],
   "source": [
    "def causal_patching(model, clean_prompts, adv_prompts, labels, panic_components_df,\n",
    "                    metadata, top_k=20, n_random_trials=5, batch_size=16):\n",
    "    \"\"\"Perform causal patching on top-K panic components.\"\"\"\n",
    "    label_tokens = get_label_token_ids(model)\n",
    "    eps = 1e-10\n",
    "\n",
    "    # Get top-K components\n",
    "    top_components = panic_components_df.head(top_k)\n",
    "\n",
    "    # Build hook dict for patching: {hook_name: [(comp_idx, ...), ...]}\n",
    "    hooks_to_patch = {}\n",
    "    for _, row in top_components.iterrows():\n",
    "        layer = row['layer']\n",
    "        comp_type = row['type']\n",
    "        comp_idx = row['index']\n",
    "\n",
    "        if comp_type == \"mlp\":\n",
    "            hook = f\"blocks.{layer}.hook_mlp_out\"\n",
    "        elif comp_type == \"attn\":\n",
    "            hook = f\"blocks.{layer}.attn.hook_z\"\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if hook not in hooks_to_patch:\n",
    "            hooks_to_patch[hook] = []\n",
    "        hooks_to_patch[hook].append((comp_idx, comp_type))\n",
    "\n",
    "\n",
    "\n",
    "    # Get baseline scores (clean and adversarial)\n",
    "    clean_scores = []\n",
    "    adv_scores = []\n",
    "\n",
    "    for i in range(0, len(clean_prompts), batch_size):\n",
    "        batch_clean = clean_prompts[i:i+batch_size]\n",
    "        batch_adv = adv_prompts[i:i+batch_size]\n",
    "        batch_labels = labels[i:i+batch_size]\n",
    "\n",
    "        clean_tokens = model.to_tokens(batch_clean)\n",
    "        adv_tokens = model.to_tokens(batch_adv)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            clean_logits = model(clean_tokens)\n",
    "            adv_logits = model(adv_tokens)\n",
    "\n",
    "            for j, label in enumerate(batch_labels):\n",
    "                if label in label_tokens:\n",
    "                    clean_prob = torch.softmax(clean_logits[j, -1, :], dim=-1)[label_tokens[label]].item()\n",
    "                    adv_prob = torch.softmax(adv_logits[j, -1, :], dim=-1)[label_tokens[label]].item()\n",
    "                    clean_scores.append(clean_prob)\n",
    "                    adv_scores.append(adv_prob)\n",
    "                else:\n",
    "                    clean_scores.append(0.0)\n",
    "                    adv_scores.append(0.0)\n",
    "\n",
    "    # Run patching - process prompts individually to handle sequence length mismatches\n",
    "    patched_scores = []\n",
    "\n",
    "    for i in range(len(adv_prompts)):\n",
    "        adv_prompt = adv_prompts[i]\n",
    "        clean_prompt = clean_prompts[i]\n",
    "        label = labels[i]\n",
    "        insertion_positions = metadata['insertion_positions'][i]\n",
    "\n",
    "        adv_tokens = model.to_tokens(adv_prompt)\n",
    "        clean_tokens = model.to_tokens(clean_prompt)\n",
    "\n",
    "        # Get clean cache\n",
    "        with torch.no_grad():\n",
    "            _, clean_cache = model.run_with_cache(clean_tokens)\n",
    "\n",
    "            # Build position mapping: clean positions to adversarial positions\n",
    "            clean_to_adv_map = {}\n",
    "            clean_len = clean_tokens.shape[1]\n",
    "            adv_len = adv_tokens.shape[1]\n",
    "\n",
    "            if insertion_positions:\n",
    "                sorted_insertions = sorted(insertion_positions)\n",
    "                for clean_pos in range(clean_len):\n",
    "                    insertions_before = sum(1 for ins_pos in sorted_insertions if ins_pos <= clean_pos)\n",
    "                    adv_pos = clean_pos + insertions_before\n",
    "                    if adv_pos < adv_len:\n",
    "                        clean_to_adv_map[clean_pos] = adv_pos\n",
    "            else:\n",
    "                for pos in range(min(clean_len, adv_len)):\n",
    "                    clean_to_adv_map[pos] = pos\n",
    "\n",
    "            # Define patching hook function\n",
    "            def make_patch_hook(hook_name, clean_acts_single):\n",
    "                def patch_hook(activations, hook):\n",
    "                    if hook.name != hook_name or hook.name not in hooks_to_patch:\n",
    "                        return activations\n",
    "\n",
    "                    # activations shape: [1, adv_seq_len, ...]\n",
    "                    # clean_acts_single shape: [1, clean_seq_len, ...]\n",
    "                    components_to_patch = hooks_to_patch[hook.name]\n",
    "                    patched = activations.clone()\n",
    "\n",
    "                    if \"mlp\" in hook.name:\n",
    "                        for comp_idx, _ in components_to_patch:\n",
    "                            for clean_pos, adv_pos in clean_to_adv_map.items():\n",
    "                                if clean_pos < clean_acts_single.shape[1] and adv_pos < activations.shape[1]:\n",
    "                                    patched[0, adv_pos, comp_idx] = clean_acts_single[0, clean_pos, comp_idx]\n",
    "                    elif \"attn\" in hook.name and \"hook_z\" in hook.name:\n",
    "                        for comp_idx, _ in components_to_patch:\n",
    "                            for clean_pos, adv_pos in clean_to_adv_map.items():\n",
    "                                if clean_pos < clean_acts_single.shape[1] and adv_pos < activations.shape[1]:\n",
    "                                    patched[0, adv_pos, comp_idx, :] = clean_acts_single[0, clean_pos, comp_idx, :]\n",
    "\n",
    "                    return patched\n",
    "                return patch_hook\n",
    "\n",
    "            # Create hooks for each hook point\n",
    "            fwd_hooks = []\n",
    "            for hook_name in hooks_to_patch.keys():\n",
    "                if hook_name in clean_cache:\n",
    "                    clean_acts_single = clean_cache[hook_name]  # [1, clean_seq_len, ...]\n",
    "                    fwd_hooks.append((hook_name, make_patch_hook(hook_name, clean_acts_single)))\n",
    "\n",
    "            # Run adversarial with patching\n",
    "            patched_logits = model.run_with_hooks(adv_tokens, fwd_hooks=fwd_hooks)\n",
    "\n",
    "            if label in label_tokens:\n",
    "                patched_prob = torch.softmax(patched_logits[0, -1, :], dim=-1)[label_tokens[label]].item()\n",
    "                patched_scores.append(patched_prob)\n",
    "            else:\n",
    "                patched_scores.append(0.0)\n",
    "\n",
    "    # Compute recovery metric\n",
    "    recoveries = []\n",
    "    for clean, adv, patched in zip(clean_scores, adv_scores, patched_scores):\n",
    "        denominator = clean - adv + eps\n",
    "        if denominator > eps:\n",
    "            recovery = (patched - adv) / denominator\n",
    "        else:\n",
    "            recovery = 0.0\n",
    "        recoveries.append(recovery)\n",
    "\n",
    "    mean_recovery = np.mean(recoveries)\n",
    "\n",
    "    # Random baseline\n",
    "    random_recoveries = []\n",
    "\n",
    "    for trial in range(n_random_trials):\n",
    "        # Sample random components from same layers\n",
    "        random_components = panic_components_df.sample(n=top_k)\n",
    "        random_hooks = {}\n",
    "\n",
    "        for _, row in random_components.iterrows():\n",
    "            layer = row['layer']\n",
    "            comp_type = row['type']\n",
    "            comp_idx = row['index']\n",
    "\n",
    "            if comp_type == \"mlp\":\n",
    "                hook = f\"blocks.{layer}.hook_mlp_out\"\n",
    "            elif comp_type == \"attn\":\n",
    "                hook = f\"blocks.{layer}.attn.hook_z\"\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if hook not in random_hooks:\n",
    "                random_hooks[hook] = []\n",
    "            random_hooks[hook].append((comp_idx, comp_type))\n",
    "\n",
    "        random_patched_scores = []\n",
    "        for i in range(len(adv_prompts)):\n",
    "            adv_prompt = adv_prompts[i]\n",
    "            clean_prompt = clean_prompts[i]\n",
    "            label = labels[i]\n",
    "            insertion_positions = metadata['insertion_positions'][i]\n",
    "\n",
    "            adv_tokens = model.to_tokens(adv_prompt)\n",
    "            clean_tokens = model.to_tokens(clean_prompt)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                _, clean_cache = model.run_with_cache(clean_tokens)\n",
    "\n",
    "                # Build position mapping (same as main patching)\n",
    "                clean_to_adv_map = {}\n",
    "                clean_len = clean_tokens.shape[1]\n",
    "                adv_len = adv_tokens.shape[1]\n",
    "\n",
    "                if insertion_positions:\n",
    "                    sorted_insertions = sorted(insertion_positions)\n",
    "                    for clean_pos in range(clean_len):\n",
    "                        insertions_before = sum(1 for ins_pos in sorted_insertions if ins_pos <= clean_pos)\n",
    "                        adv_pos = clean_pos + insertions_before\n",
    "                        if adv_pos < adv_len:\n",
    "                            clean_to_adv_map[clean_pos] = adv_pos\n",
    "                else:\n",
    "                    for pos in range(min(clean_len, adv_len)):\n",
    "                        clean_to_adv_map[pos] = pos\n",
    "\n",
    "                def make_random_patch_hook(hook_name, clean_acts_single):\n",
    "                    def random_patch_hook(activations, hook):\n",
    "                        if hook.name != hook_name or hook.name not in random_hooks:\n",
    "                            return activations\n",
    "                        components_to_patch = random_hooks[hook.name]\n",
    "                        patched = activations.clone()\n",
    "\n",
    "                        if \"mlp\" in hook.name:\n",
    "                            for comp_idx, _ in components_to_patch:\n",
    "                                for clean_pos, adv_pos in clean_to_adv_map.items():\n",
    "                                    if clean_pos < clean_acts_single.shape[1] and adv_pos < activations.shape[1]:\n",
    "                                        patched[0, adv_pos, comp_idx] = clean_acts_single[0, clean_pos, comp_idx]\n",
    "                        elif \"attn\" in hook.name and \"hook_z\" in hook.name:\n",
    "                            for comp_idx, _ in components_to_patch:\n",
    "                                for clean_pos, adv_pos in clean_to_adv_map.items():\n",
    "                                    if clean_pos < clean_acts_single.shape[1] and adv_pos < activations.shape[1]:\n",
    "                                        patched[0, adv_pos, comp_idx, :] = clean_acts_single[0, clean_pos, comp_idx, :]\n",
    "                        return patched\n",
    "                    return random_patch_hook\n",
    "\n",
    "                fwd_hooks = []\n",
    "                for hook_name in random_hooks.keys():\n",
    "                    if hook_name in clean_cache:\n",
    "                        clean_acts_single = clean_cache[hook_name]\n",
    "                        fwd_hooks.append((hook_name, make_random_patch_hook(hook_name, clean_acts_single)))\n",
    "\n",
    "                patched_logits = model.run_with_hooks(adv_tokens, fwd_hooks=fwd_hooks)\n",
    "\n",
    "                if label in label_tokens:\n",
    "                    patched_prob = torch.softmax(patched_logits[0, -1, :], dim=-1)[label_tokens[label]].item()\n",
    "                    random_patched_scores.append(patched_prob)\n",
    "                else:\n",
    "                    random_patched_scores.append(0.0)\n",
    "\n",
    "        random_recoveries_trial = []\n",
    "        for clean, adv, patched in zip(clean_scores, adv_scores, random_patched_scores):\n",
    "            denominator = clean - adv + eps\n",
    "            if denominator > eps:\n",
    "                recovery = (patched - adv) / denominator\n",
    "            else:\n",
    "                recovery = 0.0\n",
    "            random_recoveries_trial.append(recovery)\n",
    "        random_recoveries.append(np.mean(random_recoveries_trial))\n",
    "\n",
    "    mean_random_recovery = np.mean(random_recoveries)\n",
    "    std_random_recovery = np.std(random_recoveries)\n",
    "\n",
    "    results = {\n",
    "        'top_k': top_k,\n",
    "        'mean_recovery': mean_recovery,\n",
    "        'mean_random_recovery': mean_random_recovery,\n",
    "        'std_random_recovery': std_random_recovery,\n",
    "        'recoveries': recoveries,\n",
    "        'random_recoveries': random_recoveries\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "WQHWXNCcQq_s"
   },
   "outputs": [],
   "source": [
    "# Run causal patching\n",
    "patch_results = causal_patching(\n",
    "    model, clean_prompts, adv_prompts, labels, panic_components_df, metadata,\n",
    "    top_k=20, n_random_trials=5, batch_size=16\n",
    ")\n",
    "\n",
    "# Save results to CSV\n",
    "patch_df = pd.DataFrame({\n",
    "    'top_k': [patch_results['top_k']],\n",
    "    'mean_recovery': [patch_results['mean_recovery']],\n",
    "    'mean_random_recovery': [patch_results['mean_random_recovery']],\n",
    "    'std_random_recovery': [patch_results['std_random_recovery']]\n",
    "})\n",
    "patch_df.to_csv(\"artifacts/patch_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "-XyZpJLFQq_s"
   },
   "outputs": [],
   "source": [
    "# Save run manifest\n",
    "import json\n",
    "import platform\n",
    "from datetime import datetime\n",
    "\n",
    "run_manifest = {\n",
    "    \"model_id\": MODEL_NAME,\n",
    "    \"model_config\": {\n",
    "        \"n_layers\": model.cfg.n_layers,\n",
    "        \"d_model\": model.cfg.d_model,\n",
    "        \"d_mlp\": model.cfg.d_mlp,\n",
    "        \"n_heads\": model.cfg.n_heads,\n",
    "        \"d_vocab\": model.cfg.d_vocab,\n",
    "        \"n_ctx\": model.cfg.n_ctx\n",
    "    },\n",
    "    \"versions\": {\n",
    "        \"pytorch\": torch.__version__,\n",
    "        \"transformer_lens\": \"2.16.1\",  # Update if needed\n",
    "        \"python\": platform.python_version()\n",
    "    },\n",
    "    \"hardware\": {\n",
    "        \"device\": DEVICE,\n",
    "        \"dtype\": str(DTYPE),\n",
    "        \"cuda_available\": torch.cuda.is_available(),\n",
    "        \"cuda_device\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else None\n",
    "    },\n",
    "    \"experiment_config\": {\n",
    "        \"n_prompts\": len(clean_prompts),\n",
    "        \"n_candidates\": 500,\n",
    "        \"batch_size\": 32,\n",
    "        \"seed\": SEED,\n",
    "        \"top_k_patching\": 20,\n",
    "        \"n_random_trials\": 5\n",
    "    },\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(\"artifacts/run_manifest.json\", \"w\") as f:\n",
    "    json.dump(run_manifest, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "_ncMXAL1Qq_t"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(\"artifacts/plots\", exist_ok=True)\n",
    "os.makedirs(\"artifacts/tables\", exist_ok=True)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams['figure.dpi'] = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "gNzYS-1uQq_t"
   },
   "outputs": [],
   "source": [
    "# Load all artifacts\n",
    "panic_components_df = pd.read_csv(\"artifacts/panic_components.csv\")\n",
    "patch_results_df = pd.read_csv(\"artifacts/patch_results.csv\")\n",
    "\n",
    "adv_metadata = []\n",
    "with open(\"artifacts/adv_metadata.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        adv_metadata.append(json.loads(line.strip()))\n",
    "\n",
    "with open(\"artifacts/clean_prompts.txt\", \"r\") as f:\n",
    "    clean_prompts = [line.strip() for line in f if line.strip()]\n",
    "with open(\"artifacts/adv_prompts.txt\", \"r\") as f:\n",
    "    adv_prompts = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "with open(\"artifacts/run_manifest.json\", \"r\") as f:\n",
    "    run_manifest = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7wF39wSQq_u"
   },
   "source": [
    "## 8a. Layerwise Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ReUMhgPwQq_u"
   },
   "outputs": [],
   "source": [
    "# Layerwise Mean |\u0394norm| Analysis\n",
    "layerwise_stats = panic_components_df.groupby('layer')['abs_delta_norm'].mean().sort_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(layerwise_stats.index, layerwise_stats.values, color='steelblue', alpha=0.7, edgecolor='black', linewidth=1.2)\n",
    "ax.set_xlabel('Layer Index', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Mean |\u0394norm|', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Layerwise Mean |\u0394norm| Across All Components', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(layerwise_stats.index)\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (layer, value) in enumerate(layerwise_stats.items()):\n",
    "    ax.text(layer, value, f'{value:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"artifacts/plots/layerwise_delta_norm.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVg6KZ7MQq_v"
   },
   "source": [
    "## 8b. Positional Localization Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "7Q9vrdZsQq_v"
   },
   "outputs": [],
   "source": [
    "# Position-Localization Analysis\n",
    "top_k = run_manifest['experiment_config']['top_k_patching']\n",
    "top_components = panic_components_df.head(top_k)\n",
    "\n",
    "# create histogram\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.hist(top_components['abs_delta_norm'], bins=20, color='coral', alpha=0.7, edgecolor='black', linewidth=1.2)\n",
    "ax.set_xlabel('|\u0394norm| at Trigger Position', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Number of Components', fontsize=12, fontweight='bold')\n",
    "ax.set_title(f'Distribution of |\u0394norm| for Top-{top_k} Panic Components', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.axvline(top_components['abs_delta_norm'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {top_components[\"abs_delta_norm\"].mean():.2f}')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"artifacts/plots/position_localization.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "k2xO1iOnQq_w"
   },
   "outputs": [],
   "source": [
    "# \u0394norm distribution: MLP vs Attention\n",
    "mlp_delta_norm = panic_components_df[panic_components_df['type'] == 'mlp']['abs_delta_norm']\n",
    "attn_delta_norm = panic_components_df[panic_components_df['type'] == 'attn']['abs_delta_norm']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Histogram comparison\n",
    "ax1.hist(mlp_delta_norm, bins=50, alpha=0.6, label='MLP', color='steelblue', edgecolor='black', linewidth=0.5)\n",
    "ax1.hist(attn_delta_norm, bins=50, alpha=0.6, label='Attention', color='coral', edgecolor='black', linewidth=0.5)\n",
    "ax1.set_xlabel('|\u0394norm|', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Number of Components', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Distribution of |\u0394norm|: MLP vs Attention', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Box plot comparison\n",
    "box_data = [mlp_delta_norm.values, attn_delta_norm.values]\n",
    "bp = ax2.boxplot(box_data, labels=['MLP', 'Attention'], patch_artist=True,\n",
    "                 boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                 medianprops=dict(color='red', linewidth=2))\n",
    "ax2.set_ylabel('|\u0394norm|', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Box Plot: MLP vs Attention |\u0394norm|', fontsize=14, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"artifacts/plots/delta_norm_distributions.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "dFaKi6EAQq_w"
   },
   "outputs": [],
   "source": [
    "# Causal Patching Visualization\n",
    "top_k_recovery = patch_results_df['mean_recovery'].iloc[0]\n",
    "random_k_mean = patch_results_df['mean_random_recovery'].iloc[0]\n",
    "random_k_std = patch_results_df['std_random_recovery'].iloc[0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "categories = ['Top-K\\nComponents', 'Random-K\\nBaseline']\n",
    "values = [top_k_recovery, random_k_mean]\n",
    "errors = [0, random_k_std]\n",
    "colors = ['steelblue', 'coral']\n",
    "\n",
    "bars = ax.bar(categories, values, yerr=errors, capsize=10, color=colors, alpha=0.7,\n",
    "              edgecolor='black', linewidth=1.5, error_kw={'elinewidth': 2, 'capthick': 2})\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (val, err) in enumerate(zip(values, errors)):\n",
    "    if i == 0:\n",
    "        ax.text(i, val, f'{val:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    else:\n",
    "        ax.text(i, val + err, f'{val:.3f}\u00b1{err:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Recovery Metric', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Causal Patching Results: Top-K vs Random-K Baseline', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.set_ylim(bottom=0)\n",
    "\n",
    "# Add horizontal line at y=0 for reference\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"artifacts/plots/causal_patching_results.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "5nY1z_e2Qq_w"
   },
   "outputs": [],
   "source": [
    "# Top-20 Panic Components Table\n",
    "top_k = run_manifest['experiment_config']['top_k_patching']\n",
    "top_20_components = panic_components_df.head(top_k).copy()\n",
    "\n",
    "# Create formatted table with selected columns\n",
    "table_columns = ['layer', 'type', 'index', 'delta_norm', 'abs_delta_norm']\n",
    "top_20_table = top_20_components[table_columns].copy()\n",
    "top_20_table.columns = ['Layer', 'Type', 'Index', '\u0394norm', '|\u0394norm|']\n",
    "\n",
    "# Format for display\n",
    "top_20_table['Type'] = top_20_table['Type'].str.upper()\n",
    "top_20_table['\u0394norm'] = top_20_table['\u0394norm'].round(3)\n",
    "top_20_table['|\u0394norm|'] = top_20_table['|\u0394norm|'].round(3)\n",
    "\n",
    "# Save to CSV\n",
    "top_20_table.to_csv(\"artifacts/tables/top_20_components.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "8QtetqzlQrAF"
   },
   "outputs": [],
   "source": [
    "# Patch Recovery Summary Table\n",
    "top_k_recovery = patch_results_df['mean_recovery'].iloc[0]\n",
    "random_k_mean = patch_results_df['mean_random_recovery'].iloc[0]\n",
    "random_k_std = patch_results_df['std_random_recovery'].iloc[0]\n",
    "difference = top_k_recovery - random_k_mean\n",
    "\n",
    "summary_data = {\n",
    "    'Metric': ['Top-K Recovery', 'Random-K Recovery (mean)', 'Random-K Recovery (std)', 'Difference (Top-K - Random-K)'],\n",
    "    'Value': [f'{top_k_recovery:.4f}', f'{random_k_mean:.4f}', f'{random_k_std:.4f}', f'{difference:.4f}']\n",
    "}\n",
    "\n",
    "patch_summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Save to CSV\n",
    "patch_summary_df.to_csv(\"artifacts/tables/patch_recovery_summary.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}